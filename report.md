# 决策树分类实验报告

## 1. 实验目的
1. 掌握决策树算法的基本原理与实现
2. 学习使用Python进行机器学习模型开发
3. 掌握模型评估方法与可视化技术

## 2. 实验原理
决策树通过信息增益（ID3算法）选择特征进行节点分裂，构建树形结构实现分类。公式表达为：
```
信息增益 = 原始信息熵 - 特征划分后的条件熵
```

**计算过程图示**：
![信息增益计算流程](information_gain.png)

## 3. 实验步骤
1. 导入Iris鸢尾花数据集
2. 划分训练集/测试集（7:3）
3. 构建最大深度为3的决策树模型
4. 进行预测并计算准确率
5. 可视化决策树结构
6. 特征重要性分析：
```python
import pandas as pd
features = pd.DataFrame({
    '特征': data.feature_names,
    '重要性': clf.feature_importances_
})
print(features.sort_values('重要性', ascending=False))
```

## 4. 实验内容及数据处理
**数据集特征**：
- 150个样本，3个类别
- 4个特征：花萼长宽、花瓣长宽（单位：cm）

**统计描述**：
| 特征 | 均值 | 方差 |
|------|------|------|
| 花萼长度 | 5.84 | 0.68 |
| 花萼宽度 | 3.05 | 0.19 |
| 花瓣长度 | 3.76 | 3.10 |
| 花瓣宽度 | 1.20 | 0.58 |

**数据预处理**：
```python
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                   test_size=0.3,
                                   random_state=42)
```

## 5. 实验结果及讨论

**节点分裂说明**：
- 每个节点显示分裂特征及阈值（如花瓣宽度 ≤ 0.8）
- 叶子节点显示类别分布和最终分类结果

## 6. 模型优化分析
**max_depth参数对比实验**：
| 深度 | 训练集准确率 | 测试集准确率 |
|------|-------------|-------------|
| 2    | 95.24%      | 95.56%      |
| 3    | 99.05%      | 97.78%      |
| 4    | 100%        | 95.56%      |
| 5    | 100%        | 93.33%      |

*结论：当max_depth=3时模型达到最佳泛化能力*
**模型性能**：
```
模型准确率: 97.78%
```

**决策树可视化**：
![决策树结构](decision_tree.png)

**结果分析**：
- 深度限制有效防止过拟合
- 花瓣宽度是最重要分裂特征
- 在测试集上表现出较高泛化能力
```